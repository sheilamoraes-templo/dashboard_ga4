"""
Pipeline GA4 - Download e Processamento de Dados
Sistema completo para baixar dados especÃ­ficos do GA4 e disponibilizar no dashboard
"""

import os
import sys
import pandas as pd
from datetime import datetime, timedelta
import logging

# Adicionar src ao path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

try:
    from ga4_client import GA4Client
    from data_processor import data_processor
except ImportError as e:
    print(f"âŒ Erro ao importar mÃ³dulos: {e}")
    print("ğŸ”§ Verifique se os arquivos estÃ£o na pasta src/")
    sys.exit(1)

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GA4Pipeline:
    """Pipeline completo para download e processamento de dados GA4"""
    
    def __init__(self):
        self.ga4_client = None
        self.data_dir = "data"
        self.ensure_data_dir()
        
    def ensure_data_dir(self):
        """Garante que a pasta data existe"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            logger.info(f"ğŸ“ Pasta {self.data_dir} criada")
    
    def initialize_ga4_client(self):
        """Inicializa o cliente GA4"""
        try:
            self.ga4_client = GA4Client()
            logger.info("âœ… Cliente GA4 inicializado")
            return True
        except Exception as e:
            logger.error(f"âŒ Erro ao inicializar GA4: {e}")
            return False
    
    def download_main_metrics(self, days=30):
        """Baixa mÃ©tricas principais (usuÃ¡rios, sessÃµes, pageviews, etc.)"""
        logger.info(f"ğŸ“Š Baixando mÃ©tricas principais para {days} dias...")
        
        try:
            # Baixar dados bÃ¡sicos
            metrics_dict = self.ga4_client.get_basic_metrics(days=days)
            
            if metrics_dict and isinstance(metrics_dict, dict):
                # Converter dict para DataFrame
                df = pd.DataFrame([metrics_dict])
                
                # Processar dados
                df_processed = data_processor.process_dataframe(df, "kpis_daily")
                
                # Salvar CSV
                filename = "kpis_daily.csv"
                filepath = os.path.join(self.data_dir, filename)
                df_processed.to_csv(filepath, index=False)
                
                logger.info(f"âœ… MÃ©tricas principais salvas: {filename} ({len(df_processed)} registros)")
                return True
            else:
                logger.warning("âš ï¸ Nenhum dado de mÃ©tricas principais encontrado")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erro ao baixar mÃ©tricas principais: {e}")
            return False
    
    def download_top_pages(self, days=30, limit=50):
        """Baixa top pÃ¡ginas e links mais acessados"""
        logger.info(f"ğŸ“„ Baixando top {limit} pÃ¡ginas para {days} dias...")
        
        try:
            # Baixar dados de pÃ¡ginas
            df = self.ga4_client.get_top_pages(days=days, limit=limit)
            
            if df is not None and not df.empty:
                # Processar dados
                df_processed = data_processor.process_dataframe(df, "pages_top")
                
                # Salvar CSV
                filename = "pages_top.csv"
                filepath = os.path.join(self.data_dir, filename)
                df_processed.to_csv(filepath, index=False)
                
                logger.info(f"âœ… Top pÃ¡ginas salvas: {filename} ({len(df_processed)} registros)")
                return True
            else:
                logger.warning("âš ï¸ Nenhum dado de pÃ¡ginas encontrado")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erro ao baixar top pÃ¡ginas: {e}")
            return False
    
    def download_device_breakdown(self, days=30):
        """Baixa breakdown por dispositivo"""
        logger.info(f"ğŸ“± Baixando breakdown por dispositivo para {days} dias...")
        
        try:
            # Baixar dados de dispositivos
            df = self.ga4_client.get_device_breakdown(days=days)
            
            if df is not None and not df.empty:
                # Processar dados
                df_processed = data_processor.process_dataframe(df, "devices")
                
                # Salvar CSV
                filename = "devices.csv"
                filepath = os.path.join(self.data_dir, filename)
                df_processed.to_csv(filepath, index=False)
                
                logger.info(f"âœ… Breakdown por dispositivo salvo: {filename} ({len(df_processed)} registros)")
                return True
            else:
                logger.warning("âš ï¸ Nenhum dado de dispositivos encontrado")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erro ao baixar breakdown por dispositivo: {e}")
            return False
    
    def download_first_user_acquisition(self, days=30):
        """Baixa dados de primeiros acessos (source/medium)"""
        logger.info(f"ğŸ¯ Baixando primeiros acessos para {days} dias...")
        
        try:
            # Baixar dados de aquisiÃ§Ã£o
            df = self.ga4_client.get_first_user_acquisition(days=days)
            
            if df is not None and not df.empty:
                # Processar dados
                df_processed = data_processor.process_dataframe(df, "acquisition")
                
                # Salvar CSV
                filename = "first_user_acquisition.csv"
                filepath = os.path.join(self.data_dir, filename)
                df_processed.to_csv(filepath, index=False)
                
                logger.info(f"âœ… Primeiros acessos salvos: {filename} ({len(df_processed)} registros)")
                return True
            else:
                logger.warning("âš ï¸ Nenhum dado de primeiros acessos encontrado")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erro ao baixar primeiros acessos: {e}")
            return False
    
    def download_video_events(self, days=30):
        """Baixa eventos de vÃ­deo (video_start, video_progress, video_complete)"""
        logger.info(f"ğŸ¬ Baixando eventos de vÃ­deo para {days} dias...")
        
        try:
            # Baixar dados de eventos de vÃ­deo
            df = self.ga4_client.get_video_events(days=days)
            
            if df is not None and not df.empty:
                # Processar dados
                df_processed = data_processor.process_dataframe(df, "video_events")
                
                # Salvar CSV
                filename = "video_events.csv"
                filepath = os.path.join(self.data_dir, filename)
                df_processed.to_csv(filepath, index=False)
                
                logger.info(f"âœ… Eventos de vÃ­deo salvos: {filename} ({len(df_processed)} registros)")
                return True
            else:
                logger.warning("âš ï¸ Nenhum evento de vÃ­deo encontrado")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erro ao baixar eventos de vÃ­deo: {e}")
            return False
    
    def download_weekly_comparison(self, weeks=4):
        """Baixa dados para comparaÃ§Ã£o semanal"""
        logger.info(f"ğŸ“… Baixando comparaÃ§Ã£o semanal para {weeks} semanas...")
        
        try:
            # Baixar dados semanais
            df = self.ga4_client.get_weekly_comparison(weeks=weeks)
            
            if df is not None and not df.empty:
                # Processar dados
                df_processed = data_processor.process_dataframe(df, "weekly_comparison")
                
                # Salvar CSV
                filename = "weekly_comparison.csv"
                filepath = os.path.join(self.data_dir, filename)
                df_processed.to_csv(filepath, index=False)
                
                logger.info(f"âœ… ComparaÃ§Ã£o semanal salva: {filename} ({len(df_processed)} registros)")
                return True
            else:
                logger.warning("âš ï¸ Nenhum dado de comparaÃ§Ã£o semanal encontrado")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erro ao baixar comparaÃ§Ã£o semanal: {e}")
            return False
    
    def download_days_with_most_users(self, days=30):
        """Baixa dados dos dias com mais usuÃ¡rios"""
        logger.info(f"ğŸ“ˆ Baixando dias com mais usuÃ¡rios para {days} dias...")
        
        try:
            # Baixar dados diÃ¡rios detalhados
            df = self.ga4_client.get_days_with_most_users(days=days)
            
            if df is not None and not df.empty:
                # Processar dados
                df_processed = data_processor.process_dataframe(df, "days_with_most_users")
                
                # Salvar CSV
                filename = "days_with_most_users.csv"
                filepath = os.path.join(self.data_dir, filename)
                df_processed.to_csv(filepath, index=False)
                
                logger.info(f"âœ… Dias com mais usuÃ¡rios salvos: {filename} ({len(df_processed)} registros)")
                return True
            else:
                logger.warning("âš ï¸ Nenhum dado de dias com mais usuÃ¡rios encontrado")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erro ao baixar dias com mais usuÃ¡rios: {e}")
            return False
    
    def run_full_pipeline(self, days=30):
        """Executa o pipeline completo"""
        logger.info("ğŸš€ Iniciando pipeline completo de dados GA4...")
        
        # Inicializar cliente GA4
        if not self.initialize_ga4_client():
            logger.error("âŒ Falha ao inicializar cliente GA4. Pipeline interrompido.")
            return False
        
        # Lista de downloads
        downloads = [
            ("MÃ©tricas Principais", lambda: self.download_main_metrics(days)),
            ("Top PÃ¡ginas", lambda: self.download_top_pages(days)),
            ("Breakdown por Dispositivo", lambda: self.download_device_breakdown(days)),
            ("Primeiros Acessos", lambda: self.download_first_user_acquisition(days)),
            ("Eventos de VÃ­deo", lambda: self.download_video_events(days)),
            ("ComparaÃ§Ã£o Semanal", lambda: self.download_weekly_comparison()),
            ("Dias com Mais UsuÃ¡rios", lambda: self.download_days_with_most_users(days))
        ]
        
        # Executar downloads
        success_count = 0
        total_count = len(downloads)
        
        for name, download_func in downloads:
            logger.info(f"ğŸ“¥ Executando: {name}")
            try:
                if download_func():
                    success_count += 1
                    logger.info(f"âœ… {name} - ConcluÃ­do")
                else:
                    logger.warning(f"âš ï¸ {name} - Falhou")
            except Exception as e:
                logger.error(f"âŒ {name} - Erro: {e}")
        
        # Resumo final
        logger.info(f"ğŸ‰ Pipeline concluÃ­do: {success_count}/{total_count} downloads bem-sucedidos")
        
        if success_count > 0:
            logger.info("ğŸ“Š Dados disponÃ­veis no dashboard Streamlit!")
            logger.info("ğŸŒ Execute: streamlit run streamlit_dashboard.py")
        
        return success_count > 0
    
    def run_quick_pipeline(self, days=7):
        """Executa pipeline rÃ¡pido com dados essenciais"""
        logger.info("âš¡ Iniciando pipeline rÃ¡pido...")
        
        if not self.initialize_ga4_client():
            return False
        
        # Downloads essenciais
        essential_downloads = [
            ("MÃ©tricas Principais", lambda: self.download_main_metrics(days)),
            ("Top PÃ¡ginas", lambda: self.download_top_pages(days)),
            ("Breakdown por Dispositivo", lambda: self.download_device_breakdown(days))
        ]
        
        success_count = 0
        for name, download_func in essential_downloads:
            if download_func():
                success_count += 1
        
        logger.info(f"âš¡ Pipeline rÃ¡pido concluÃ­do: {success_count}/{len(essential_downloads)} downloads")
        return success_count > 0

def main():
    """FunÃ§Ã£o principal para execuÃ§Ã£o do pipeline"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Pipeline GA4 - Download de Dados")
    parser.add_argument("--days", type=int, default=30, help="NÃºmero de dias para baixar (padrÃ£o: 30)")
    parser.add_argument("--quick", action="store_true", help="Executar pipeline rÃ¡pido (7 dias)")
    parser.add_argument("--full", action="store_true", help="Executar pipeline completo")
    
    args = parser.parse_args()
    
    # Criar pipeline
    pipeline = GA4Pipeline()
    
    if args.quick:
        # Pipeline rÃ¡pido
        success = pipeline.run_quick_pipeline(days=7)
    elif args.full:
        # Pipeline completo
        success = pipeline.run_full_pipeline(days=args.days)
    else:
        # Pipeline padrÃ£o (mÃ©tricas principais + top pÃ¡ginas)
        logger.info("ğŸ“Š Executando pipeline padrÃ£o...")
        if pipeline.initialize_ga4_client():
            success = (
                pipeline.download_main_metrics(args.days) and
                pipeline.download_top_pages(args.days) and
                pipeline.download_device_breakdown(args.days)
            )
        else:
            success = False
    
    if success:
        logger.info("ğŸ‰ Pipeline executado com sucesso!")
        logger.info("ğŸŒ Execute o dashboard: streamlit run streamlit_dashboard.py")
    else:
        logger.error("âŒ Pipeline falhou. Verifique as credenciais GA4.")

if __name__ == "__main__":
    main()
